├── README.md
├── requirements.txt
├── .gitignore
│
├── data/
│   ├── raw/                # Raw scraped data (JSON corpus files)
│   ├── processed/          # Cleaned/normalized corpus
│   ├── index/              # BM25 or vector index files
│   └── samples/            # Example input/output for demonstration
│
├── src/
│   ├── data_collection/    # Phase 0: Web data gathering ✅
│   │   ├── web_search.py      # Query generation & search APIs (SerpApi, Bing)
│   │   ├── web_scraper.py     # Web scraping (trafilatura, newspaper3k)
│   │   ├── collector.py       # Complete pipeline orchestrator
│   │   └── __init__.py
│   │
│   ├── retrieval/          # Phase 1: Indexing & Retrieval (Funnel Architecture) ✅
│   │   ├── build_index.py        # Build BM25 + FAISS indexes from corpus
│   │   ├── bm25_retriever.py     # BM25 lexical search (Stage 1: Top 50)
│   │   └── embed_retriever.py    # Semantic search with embeddings
│   │
│   ├── nli/                # Phase 2: Natural Language Inference
│   │   ├── nli_model.py          # Wrapper around RoBERTa-base-MNLI
│   │   ├── batch_inference.py    # Batch processing for efficiency
│   │   [[└── onnx_model/           # ONNX-optimized version]] --> not yet
│   │
│   ├── aggregation/        # Phase 3: Scoring & aggregation
│   │   ├── scoring.py            # Numerical scoring from NLI outputs
│   │   ├── voting.py             # Majority voting aggregation
│   │   └── final_decision.py     # Final verdict with confidence
│   │
│   ├── pipeline/           # End-to-end orchestration
│   │   └── fact_check.py         # Complete pipeline:
│   │                             # claim → collect_data → build_index → 
│   │                             # retrieve (BM25+Embedding) → NLI → aggregate → verdict
│   │
│   ├── config/
│   │   └── paths.py              # Project paths configuration
│   │
│   └── utils/
│       ├── preprocessing.py      # Text preprocessing utilities
│       ├── evaluation.py         # Evaluation metrics
│       ├── metadata.py           # Metadata extraction & scoring [NEW]
│       └── helpers.py            # General helper functions
│
├── notebooks/
│   ├── exploratory_data.ipynb      # Inspect dataset
│   ├── retrieval_testing.ipynb     # Try BM25 + embedding ranking
│   ├── nli_evaluation.ipynb        # Test NLI accuracy on claims
│   [[└── pipeline_demo.ipynb         # Demo for report]] --> not yet