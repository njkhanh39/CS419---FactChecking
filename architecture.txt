├── README.md
├── requirements.txt
├── .gitignore
│
├── data/
│   ├── raw/                # Raw scraped data (JSON corpus files)
│   ├── processed/          # Cleaned/normalized corpus
│   ├── index/              # BM25 or vector index files
│   └── samples/            # Example input/output for demonstration
│
├── src/
│   ├── data_collection/    # Phase 0: Web data gathering [NEW]
│   │   ├── web_search.py      # Query generation & search APIs (SerpApi, Bing)
│   │   ├── web_scraper.py     # Web scraping (trafilatura, newspaper3k)
│   │   ├── collector.py       # Complete pipeline orchestrator
│   │   └── __init__.py
│   │
│   ├── retrieval/          # Phase 1-2: IR pipeline (Funnel Stage 1)
│   │   ├── bm25_retriever.py     # Implements lexical search (BM25)
│   │   ├── embed_retriever.py    # Implements semantic search
│   │   └── build_index.py        # Utility script for offline indexing
│   │
│   ├── sentence_ranker/    # Phase 3: Sentence ranking (Funnel Stage 2)
│   │   ├── split_sentences.py    # Break documents into sentences
│   │   ├── rank_sentences.py     # Score & rank: semantic + BM25 + metadata
│   │   └── filters.py            # Entity/keyword/metadata filters
│   │
│   ├── nli/                # Phase 4: Natural Language Inference
│   │   ├── nli_model.py          # Wrapper around RoBERTa-base-MNLI
│   │   ├── batch_inference.py    # Batch processing for efficiency
│   │   [[└── onnx_model/           # ONNX-optimized version]] --> not yet
│   │
│   ├── aggregation/        # Phase 5: Scoring & aggregation
│   │   ├── voting.py             # Majority voting aggregation
│   │   ├── scoring.py            # Numerical scoring from NLI outputs
│   │   └── final_decision.py     # Final verdict with confidence
│   │
│   ├── pipeline/           # End-to-end orchestration
│   │   └── fact_check.py         # Complete pipeline:
│   │                             # claim → search → scrape → retrieve → 
│   │                             # rank → NLI → verdict
│   │
│   ├── config/
│   │   └── paths.py              # Project paths configuration
│   │
│   └── utils/
│       ├── preprocessing.py      # Text preprocessing utilities
│       ├── evaluation.py         # Evaluation metrics
│       ├── metadata.py           # Metadata extraction & scoring [NEW]
│       └── helpers.py            # General helper functions
│
├── notebooks/
│   ├── exploratory_data.ipynb      # Inspect dataset
│   ├── retrieval_testing.ipynb     # Try BM25 + embedding ranking
│   ├── nli_evaluation.ipynb        # Test NLI accuracy on claims
│   [[└── pipeline_demo.ipynb         # Demo for report]] --> not yet